<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Bài 2: Phân nhóm các thuật toán Machine Learning</title>
</head>
<body>
<header>
<!--Giữa màn hình-->
    <h1>Machine Learning cơ bản</h1>

    <nav><!--thẻ nội dung chính-->
        <ul>
            <li><a href="#">About</a></li>
            <li><a href="#">Index</a></li>
            <li><a href="#">Tags</a></li>
            <li><a href="#">Categories</a></li>
            <li><a href="#">Archive</a></li>
            <li><a href="#">Math</a></li>
            <li><a href="#">Copyrights</a></li>
            <li><a href="#">ebook</a></li>
            <li><a href="#">Search</a></li>
        </ul>
    </nav>
    <hr>
</header>
<aside> <!--thẻ nội dung phụ-->
    <h2>Latest</h2>
    <ul>
        <li><a href="#">Con đường học PhD của tôi</a></li>
        <li><a href="#">37. Tích chập hai chiều</a></li>
        <li><a href="#">36. Keras</a></li>
        <li><a href="#">35. Lược sử Deep Learning</a></li>
        <li><a href="#">34. Decision Trees (1): ID3</a></li>
        <li><a href="#">33. Đánh giá hệ thống phân lớp</a></li>
        <li><a href="#">FundaML 3: Các mảng ngẫu nhiên</a></li>
        <li><a href="#">FundaML 2: Ma trận</a></li>
        <li><a href="#">FundaML 1: Mảng một chiều</a></li>
        <li><a href="#">FundaML.com</a></li>
        <li><a href="#">32. Naive Bayes Classifier</a></li>
        <li><a href="#">Viết và nhận xét các bài báo khoa học</a></li>
        <li><a href="#">31. Maximum Likelihood và Maximum A Posteriori</a></li>
        <li><a href="#">Con đường học Toán của tôi</a></li>
        <li><a href="#">30. Ôn tập Xác Suất</a></li>
        <li><a href="#">Q2. Transfer Learning</a></li>
        <li><a href="#">29. Linear Discriminant Analysis</a></li>
        <li><a href="#">Q1. Quick Notes 1</a></li>
        <li><a href="#">28. Principal Component Analysis (2/2)</a></li>
        <li><a href="#">27. Principal Component Analysis (1/2)</a></li>
        <li><a href="#">26. Singular Value Decomposition</a></li>
        <li><a href="#">25. Matrix Factorization Collaborative Filtering
        </a></li>
        <li><a href="#">24. Neighborhood-Based Collaborative Filtering
        </a></li>
        <li><a href="#">23. Content-based Recommendation Systems
        </a></li>
        <li><a href="#">22. Multi-class SVM</a></li>
        <li><a href="#">21. Kernel SVM</a></li>
        <li><a href="#">20. Soft Margin SVM</a></li>
        <li><a href="#">19. Support Vector Machine</a></li>
        <li><a href="#">18. Duality</a></li>
        <li><a href="#">17. Convex Optimization Problems</a></li>
        <li><a href="#">16. Convex sets và convex functions</a></li>
        <li><a href="#">15. Overfitting</a></li>
        <li><a href="#">14. Multi-layer Perceptron và Backpropagation</a></li>
        <li><a href="#">13. Softmax Regression</a></li>
        <li><a href="#">12. Binary Classifiers</a></li>
        <li><a href="#">11. Feature Engineering</a></li>
        <li><a href="#">10. Logistic Regression</a></li>
        <li><a href="#">9. Perceptron Learning Algorithm</a></li>
        <li><a href="#">8. Gradient Descent (2/2)
        </a></li>
        <li><a href="#">7. Gradient Descent (1/2)</a></li>
        <li><a href="#">6. K-nearest neighbors
        </a></li>
        <li><a href="#">5. K-means Clustering - Applications</a></li>
        <li><a href="#">4. K-means Clustering</a></li>
        <li><a href="#">3. Linear Regression</a></li>
        <li><a href="#">2. Phân nhóm các thuật toán Machine Learning</a></li>
        <li><a href="#">1. Giới thiệu về Machine Learning</a></li>
    </ul>
    <hr>
     <!--Cột bên trái-->
        <h3>SHARE</h3>
        <p>
            <a href="#">Facebook Share</a> |
            <a href="#">Email</a> |
            <a href="#">Print</a>
        </p>

        <h3>Diễn đàn</h3>
        <a href="https://forum.machinelearningcoban.com/">
            <img src="diendan.png" alt="Forum" width="200">
        </a>

        <h3>Interactive Learning</h3>
        <a href="https://fundaml.com/">
            <img src="fun.png" alt="Fundy" width="200">
        </a>

        <h3>Facebook Page</h3>
        <a href="https://www.facebook.com/machinelearningbasicvn?ref=embed_page">
            <img src="1.png" alt="Facebook Page" width="200">
        </a>

        <h3>Facebook Group</h3>
        <a href="https://www.facebook.com/groups/257768141347267/">
            <img src="2.png" alt="Facebook Group" width="200">
        </a>

        <h3>Recommended Books</h3>
        <ul>
            <li><a href="#">"Pattern Recognition and Machine Learning" – C. Bishop</a></li>
            <li><a href="#">"The Elements of Statistical Learning" – T. Hastie et al.</a></li>
            <li><a href="#">"Computer Vision: Models, Learning, and Inference" – S. Prince</a></li>
            <li><a href="#">"Convex Optimization" – Boyd & Vandenberghe</a></li>
        </ul>
        <h3>Recommended courses</h3>
        <ul>
            <li><a href="#">"Machine Learning", Andrew Ng
            </a></li>
            <li><a href="#">CS224n: Natural Language Processing with Deep Learning</a></li>
            <li><a href="#">CS231n: Convolutional Neural Networks for Visual Recognition
            </a></li>
            <li><a href="#">CS246: Mining Massive Data Sets</a></li>
            <li><a href="#">CS20SI: Tensorflow for Deep Learning Research
            </a></li>
            <li><a href="#">Introduction to Computer Science and Programming Using Python</a></li>
        </ul>
        <h3>Others</h3>
        <ul>
            <li><a href="#">Top-down learning path: Machine Learning for Software Engineers
            </a></li>
            <li><a href="#">Blog này được tạo như thế nào?</a></li>
            <li><a href="#">Chúng tôi đã apply và học tiến sỹ như thế nào? (1/2)
            </a></li>
            <li><a href="#">Chúng tôi đã apply và học tiến sỹ như thế nào? (2/2)
            </a></li>
            <li><a href="#">8 Inspirational Applications of Deep Learning
            </a></li>
            <li><a href="#">Matrix calculus</a></li>
            <li><a href="#">TensorFlow-Examples</a></li>
            <li><a href="#">Eight Easy Steps To Get Started Learning Artificial Intelligence</a></li>
            <li><a href="#">The 9 Deep Learning Papers You Need To Know About</a></li>
        </ul>
</aside>
<hr>
<main>
    <article>
        <p><a href="#">« Bài 1: Giới thiệu về Machine Learning</a>  |  <a href="#">Bài 3: Linear Regression »</a></p>

        <h2>Bài 2: Phân nhóm các thuật toán Machine Learning</h2>

        <p><strong>General</strong> <time datetime="2016-12-27">Dec 27, 2016</time></p>

        <p>Có hai cách phổ biến phân nhóm các thuật toán Machine learning. Một là dựa trên phương thức học (learning style), hai là dựa trên chức năng (function) (của mỗi thuật toán).</p>

        <h3>Trong trang này:</h3>
        <ul>
            <li><a href="#">1. Phân nhóm dựa trên phương thức học</a>
                <ul>
                    <li><a href="#">Supervised Learning (Học có giám sát)</a>
                        <ul>
                            <li><a href="#">Classification (Phân loại)</a></li>
                            <li><a href="#">Regression (Hồi quy)</a></li>
                        </ul>
                    </li>
                    <li><a href="#">Unsupervised Learning (Học không giám sát)</a>
                        <ul>
                            <li><a href="#">Clustering (phân nhóm)</a></li>
                            <li><a href="#">Association</a></li>
                        </ul>
                    </li>
                    <li><a href="#">Semi-Supervised Learning (Học bán giám sát)</a></li>
                    <li><a href="#">Reinforcement Learning (Học Củng Cố)</a></li>
                </ul>
            </li>
            <li><a href="#">2. Phân nhóm dựa trên chức năng</a>
                <ul>
                    <li><a href="#">Regression Algorithms</a></li>
                    <li><a href="#">Classification Algorithms</a></li>
                    <li><a href="#">Instance-based Algorithms</a></li>
                    <li><a href="#">Regularization Algorithms</a></li>
                    <li><a href="#">Bayesian Algorithms</a></li>
                    <li><a href="#">Clustering Algorithms</a></li>
                    <li><a href="#">Artificial Neural Network Algorithms</a></li>
                    <li><a href="#">Dimensionality Reduction Algorithms</a></li>
                    <li><a href="#">Ensemble Algorithms</a></li>
                </ul>
            </li>
            <li><a href="#">3. Tài liệu tham khảo</a></li>
        </ul>

        <h3>1. Phân nhóm dựa trên phương thức học</h3>
        <p>Theo phương thức học, các thuật toán Machine Learning thường được chia làm 4 nhóm: Supervised learning, Unsupervised learning, Semi-supervised learning và Reinforcement learning. <i>Có một số cách phân nhóm không có Semi-supervised learning hoặc Reinforcement learning.</i></p>

        <h4>Supervised Learning (Học có giám sát)</h4>
        <p>Supervised learning là thuật toán dự đoán đầu ra (outcome) của một dữ liệu mới (new input) dựa trên các cặp (input, outcome) đã biết từ trước. Cặp dữ liệu này còn được gọi là (data, label), tức (dữ liệu, nhãn). Supervised learning là nhóm phổ biến nhất trong các thuật toán Machine Learning.<p>
        <br>
        <p>Một cách toán học, Supervised learning là khi chúng ra có một tập hợp biến đầu vào X = {x1,x2,…,xN}và một tập hợp nhãn tương ứngY={y1,y2,…,yN}, trong đóxi,yilà các vector. Các cặp dữ liệu biết trước(xi,yi)∈X×Y được gọi là tập training data (dữ liệu huấn luyện). Từ tập training data này, chúng ta cần tạo ra một hàm số ánh xạ mỗi phần tử từ tập Xsang một phần tử (xấp xỉ) tương ứng của tập Y:</p>
        <br>
         <p> yi≈f(xi),  ∀i=1,2,…,N</p>
<!--        <h5>Ví dụ 1:</h5>-->
        <p><b>Ví dụ 1:</b> trong nhận dạng chữ viết tay, ta có ảnh của hàng nghìn ví dụ của mỗi chữ số được viết bởi nhiều người khác nhau. Chúng ta đưa các bức ảnh này vào trong một thuật toán và chỉ cho nó biết mỗi bức ảnh tương ứng với chữ số nào. Sau khi thuật toán tạo ra một mô hình, tức một hàm số mà đầu vào là một bức ảnh và đầu ra là một chữ số, khi nhận được một bức ảnh mới mà mô hình <b>chưa nhìn thấy bao giờ</b>, nó sẽ dự đoán bức ảnh đó chứa chữ số nào.</p>

        <!-- Image placeholder (kept in HTML-only) -->
        <p><img src="2.png" alt="MNIST example"></p>
        <p>Ví dụ này khá giống với cách học của con người khi còn nhỏ. Ta đưa bảng chữ cái cho một đứa trẻ và chỉ cho chúng đây là chữ A, đây là chữ B. Sau một vài lần được dạy thì trẻ có thể nhận biết được đâu là chữ A, đâu là chữ B trong một cuốn sách mà chúng chưa nhìn thấy bao giờ.</p>
<!--        <h5>Ví dụ 2:</h5>-->
        <p><b>Ví dụ 2:</b> Thuật toán dò các khuôn mặt trong một bức ảnh đã được phát triển từ rất lâu. Thời gian đầu, facebook sử dụng thuật toán này để chỉ ra các khuôn mặt trong một bức ảnh và yêu cầu người dùng tag friends - tức gán nhãn cho mỗi khuôn mặt. Số lượng cặp dữ liệu (khuôn mặt, tên người) càng lớn, độ chính xác ở những lần tự động tag tiếp theo sẽ càng lớn.</p>
        <p><b>Ví dụ 3:</b> Bản thân thuật toán dò tìm các khuôn mặt trong 1 bức ảnh cũng là một thuật toán Supervised learning với training data (dữ liệu học) là hàng ngàn cặp (ảnh, mặt người) và (ảnh, không phải mặt người) được đưa vào. Chú ý là dữ liệu này chỉ phân biệt mặt người và không phải mặt người mà không phân biệt khuôn mặt của những người khác nhau.</p>
        <h4>Unsupervised Learning (Học không giám sát)</h4>
        <p>Trong thuật toán này, ta không biết được outcome hay nhãn mà chỉ có dữ liệu đầu vào. Thuật toán unsupervised learning sẽ dựa vào cấu trúc của dữ liệu để thực hiện công việc như phân nhóm hoặc giảm số chiều.</p>
        <br>
        <p>Thuật toán supervised learning còn được tiếp tục chia nhỏ ra thành hai loại chính:</p>
        <h4>Classification (Phân loại)</h4>
        <p>Một bài toán được gọi là classification nếu các label của input data được chia thành một số hữu hạn nhóm. Ví dụ: Gmail xác định xem một email có phải là spam hay không; các hãng tín dụng xác định xem một khách hàng có khả năng thanh toán nợ hay không. Ba ví dụ phía trên được chia vào loại này.</p>

         <h4>Regression (Hồi quy)</h4>                        
        <p>(tiếng Việt dịch là Hồi quy, tôi không thích cách dịch này vì bản thân không hiểu nó nghĩa là gì)</p>
        <p>Nếu label không được chia thành các nhóm mà là một giá trị thực cụ thể. Ví dụ: một căn nhà rộng x m<sup>2</sup> , có y phòng ngủ và cách trung tâm thành phố z km sẽ có giá là bao nhiêu?</p>
        <p>Gần đây <a href="http://how-old.net/">Microsoft có một ứng dụng dự đoán giới tính và tuổi dựa trên khuôn mặt</a>. Phần dự đoán giới tính có thể coi là thuật toán <b></b>Classification</b>, phần dự đoán tuổi có thể coi là thuật toán <b>Regression</b>. Chú ý rằng phần dự đoán tuổi cũng có thể coi là <b>Classification</b> nếu ta coi tuổi là một số nguyên dương không lớn hơn 150, chúng ta sẽ có 150 class (lớp) khác nhau.</p>

        <h4>Semi-Supervised Learning (Học bán giám sát)</h4>
        <p>Những bài toán khi có một lượng lớn dữ liệu nhưng chỉ một phần được gán nhãn gọi là Semi-Supervised Learning.</p>

        <h4>Unsupervised Learning (Học không giám sát)</h4>
        <p>Trong thuật toán này, chúng ta không biết được outcome hay nhãn mà chỉ có dữ liệu đầu vào. Thuật toán unsupervised learning sẽ dựa vào cấu trúc của dữ liệu để thực hiện một công việc nào đó, ví dụ như phân nhóm (clustering) hoặc giảm số chiều của dữ liệu (dimension reduction) để thuận tiện trong việc lưu trữ và tính toán.</p>
         <p>
             Một cách toán học, Unsupervised learning là khi chúng ta chỉ có dữ liệu vào X mà không biết nhãn tương ứng.
         </p>
        <p>Những thuật toán loại này được gọi là Unsupervised learning vì không giống như Supervised learning, chúng ta không biết câu trả lời chính xác cho mỗi dữ liệu đầu vào. Giống như khi ta học, không có thầy cô giáo nào chỉ cho ta biết đó là chữ A hay chữ B. Cụm không giám sát được đặt tên theo nghĩa này.</p>
        <p>Các bài toán Unsupervised learning được tiếp tục chia nhỏ thành hai loại:</p>

        <h4>Clustering (phân nhóm)</h4>
        <p>Một bài toán phân nhóm toàn bộ dữ liệu X thành các nhóm nhỏ dựa trên sự liên quan giữa các dữ liệu trong mỗi nhóm. Ví dụ: phân nhóm khách hàng dựa trên hành vi mua hàng. Điều này cũng giống như việc ta đưa cho một đứa trẻ rất nhiều mảnh ghép với các hình thù và màu sắc khác nhau, ví dụ tam giác, vuông, tròn với màu xanh và đỏ, sau đó yêu cầu trẻ phân chúng thành từng nhóm. Mặc dù không cho trẻ biết mảnh nào tương ứng với hình nào hoặc màu nào, nhiều khả năng chúng vẫn có thể phân loại các mảnh ghép theo màu hoặc hình dạng.</p>

        <h4>Association</h4>
        <p>Là bài toán khi chúng ta muốn khám phá ra một quy luật dựa trên nhiều dữ liệu cho trước. Ví dụ: những khách hàng nam mua quần áo thường có xu hướng mua thêm đồng hồ hoặc thắt lưng; những khán giả xem phim Spider Man thường có xu hướng xem thêm phim Bat Man, dựa vào đó tạo ra một hệ thống gợi ý khách hàng (Recommendation System), thúc đẩy nhu cầu mua sắm.</p>

        <h4>Semi-Supervised Learning (Học bán giám sát)</h4>
        <p>Các bài toán khi chúng ta có một lượng lớn dữ liệu X nhưng chỉ một phần trong chúng được gán nhãn được gọi là Semi-Supervised Learning. Những bài toán thuộc nhóm này nằm giữa hai nhóm được nêu bên trên.</p>
        <p>Một ví dụ điển hình của nhóm này là chỉ có một phần ảnh hoặc văn bản được gán nhãn (ví dụ bức ảnh về người, động vật hoặc các văn bản khoa học, chính trị) và phần lớn các bức ảnh/văn bản khác chưa được gán nhãn được thu thập từ internet. Thực tế cho thấy rất nhiều các bài toán Machine Learning thuộc vào nhóm này vì việc thu thập dữ liệu có nhãn tốn rất nhiều thời gian và có chi phí cao. Rất nhiều loại dữ liệu thậm chí cần phải có chuyên gia mới gán nhãn được (ảnh y học chẳng hạn). Ngược lại, dữ liệu chưa có nhãn có thể được thu thập với chi phí thấp từ internet.</p>

        <h4>Reinforcement Learning (Học Củng Cố)</h4>
        <p>Reinforcement learning là các bài toán giúp cho một hệ thống tự động xác định hành vi dựa trên hoàn cảnh để đạt được lợi ích cao nhất (maximizing the performance). Hiện tại, Reinforcement learning chủ yếu được áp dụng vào Lý Thuyết Trò Chơi (Game Theory), các thuật toán cần xác định nước đi tiếp theo để đạt được điểm số cao nhất.</p>
        <img src="4.png" alt="AlphaGo chơi cờ vây với Lee Sedol."><p><small>AlphaGo chơi cờ vây với Lee Sedol. AlphaGo là một ví dụ của Reinforcement learning.</small></p>
        <p><small>(Nguồn: <a href="http://www.tomshardware.com/news/alphago-defeats-sedol-second-time,31377.html">AlphaGo AI Defeats Sedol Again, With 'Near Perfect Game'</a>)</small></p>
        <p><b>Ví dụ 1</b>: <a href="https://gogameguru.com/tag/deepmind-alphago-lee-sedol/">AlphaGo gần đây nổi tiếng với việc chơi cờ vây thắng cả con người</a>. <a href="https://www.tastehit.com/blog/google-deepmind-alphago-how-it-works/"> Cờ vây được xem là có độ phức tạp cực kỳ cao</a> với tổng số nước đi là xấp xỉ 10<sup>761</sup>, so với cờ vua là 10 <sup>120</sup> và tổng số nguyên tử trong toàn vũ trụ là khoảng 10<sup>80</sup>!! Vì vậy, thuật toán phải chọn ra 1 nước đi tối ưu trong số hàng nhiều tỉ tỉ lựa chọn, và tất nhiên, không thể áp dụng thuật toán tương tự như <a href="https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)">IBM Deep Blue</a> (IBM Deep Blue đã thắng con người trong môn cờ vua 20 năm trước). Về cơ bản, AlphaGo bao gồm các thuật toán thuộc cả Supervised learning và Reinforcement learning. Trong phần Supervised learning, dữ liệu từ các ván cờ do con người chơi với nhau được đưa vào để huấn luyện. Tuy nhiên, mục đích cuối cùng của AlphaGo không phải là chơi như con người mà phải thậm chí thắng cả con người. Vì vậy, sau khi học xong các ván cờ của con người, AlphaGo tự chơi với chính nó với hàng triệu ván chơi để tìm ra các nước đi mới tối ưu hơn. Thuật toán trong phần tự chơi này được xếp vào loại Reinforcement learning. (Xem thêm tại <a href="https://www.tastehit.com/blog/google-deepmind-alphago-how-it-works/">Google DeepMind’s AlphaGo: How it works</a>).</p>

        <p><b>Ví dụ 2</b> <a href="https://www.youtube.com/watch?v=qv6UVOQ0F44">Huấn luyện cho máy tính chơi game Mario</a>. Đây là một chương trình thú vị dạy máy tính chơi game Mario. Game này đơn giản hơn cờ vây vì tại một thời điểm, người chơi chỉ phải bấm một số lượng nhỏ các nút (di chuyển, nhảy, bắn đạn) hoặc không cần bấm nút nào. Đồng thời, phản ứng của máy cũng đơn giản hơn và lặp lại ở mỗi lần chơi (tại thời điểm cụ thể sẽ xuất hiện một chướng ngại vật cố định ở một vị trí cố định). Đầu vào của thuật toán là sơ đồ của màn hình tại thời điểm hiện tại, nhiệm vụ của thuật toán là với đầu vào đó, tổ hợp phím nào nên được bấm. Việc huấn luyện này được dựa trên điểm số cho việc di chuyển được bao xa trong thời gian bao lâu trong game, càng xa và càng nhanh thì được điểm thưởng càng cao (điểm thưởng này không phải là điểm của trò chơi mà là điểm do chính người lập trình tạo ra). Thông qua huấn luyện, thuật toán sẽ tìm ra một cách tối ưu để tối đa số điểm trên, qua đó đạt được mục đích cuối cùng là cứu công chúa.</p>
        <iframe width="600" height="400" src="https://www.youtube.com/embed/qv6UVOQ0F44" title="MarI/O - Machine Learning for Video Games" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        <p>Huấn luyện cho máy tính chơi game Mario</p>

        <h4>2. Phân nhóm dựa trên chức năng</h4>
        <p>Có một cách phân nhóm thứ hai dựa trên chức năng của các thuật toán. Trong phần này, tôi xin chỉ liệt kê các thuật toán. Thông tin cụ thể sẽ được trình bày trong các bài viết khác tại blog này. Trong quá trình viết, tôi có thể sẽ thêm bớt một số thuật toán.</p>
        
        <h4>Regression Algorithms</h4>
        <ol>
          <li><a href="#">Linear Regression</a></li>
          <li><a href="#">Logistic Regression</a></li>
          <li>Stepwise Regression</li>
        </ol>

        <h4>Classification Algorithms</h4>
        <ol>
          <li>Linear Classifier</li>
          <li><a href="#">Support Vector Machine (SVM)</a></li>
          <li><a href="#">Kernel SVM</a></li>
          <li>Sparse Representation-based classification (SRC)</li>
        </ol>

         <h4>Instance-based Algorithms</h4>
         <ol>                                          
           <li><a href="#">k-Nearest Neighbor (kNN)</a></li>
           <li>Learning Vector Quantization (LVQ)</li>
         </ol>

        <h4>Regularization Algorithms</h4>
        <ol>
            <li>Ridge Regression</li>
            <li>Least Absolute Shrinkage and Selection Operator (LASSO)</li>
            <li>Least-Angle Regression (LARS)</li>
        </ol>

        <h4>Bayesian Algorithms</h4>
        <ol>
            <li>Naive Bayes</li>
            <li>Gaussian Naive Bayes</li>
        </ol>

        <h4>Clustering Algorithms</h4>
        <ol>
            <li><a href="#">k-Means clustering</a></li>
            <li>k-Medians</li>
            <li>Expectation Maximization (EM)</li>
        </ol>

        <h4>Artificial Neural Network Algorithms</h4>
        <ol>
            <li><a href="#">Perceptron</a></li>
            <li><a href="#">Softmax Regression</a></li>
            <li><a href="#">Multi-layer Perceptron</a></li>
            <li><a href="#">Back-Propagation</a></li>
        </ol>

        <h4>Dimensionality Reduction Algorithms</h4>
        <ol>
            <li><a href="#">Principal Component Analysis (PCA)</a></li>
            <li><a href="#">Linear Discriminant Analysis (LDA)</a></li>
        </ol>

        <h4>Ensemble Algorithms</h4>
        <ol>
            <li>Boosting</li>
            <li>AdaBoost</li>
            <li>Random Fores</li>
        </ol>
        <p>Và còn rất nhiều các thuật toán khác.</p>
        <hr>
        <h3>Tài liệu tham khảo</h3>
        <ol>
            <li><a href="#">A Tour of Machine Learning Algorithms</a></li>
            <li><a href="#">Điểm qua các thuật toán Machine Learning hiện đại</a></li>
        </ol>
        <hr>
        <p>Nếu có câu hỏi, Bạn có thể để lại comment bên dưới hoặc trên <a href="https://www.facebook.com/groups/257768141347267/"> Forum</a> để nhận được câu trả lời sớm hơn.
            Bạn đọc có thể ủng hộ blog qua <a href="https://machinelearningcoban.com/buymeacoffee/"> 'Buy me a cofee'</a> ở góc trên bên trái của blog.
            Tôi vừa hoàn thành cuốn ebook 'Machine Learning cơ bản', bạn có thể đặt sách <a href="https://machinelearningcoban.com/ebook/"> tại đây</a>. Cảm ơn bạn.</p>
        <hr>
        <p><a href="#">« Bài 1: Giới thiệu về Machine Learning</a>  |  <a href="#">Bài 3: Linear Regression »</a></p>
    </article>
</main>
</body>
</html>
